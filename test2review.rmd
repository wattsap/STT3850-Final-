##Test 2 Study guide:

```{r, setup}
library(datasets)
library(gtools)
```


#### Utilities/Random ass functions and what they do

###### Randomly Sampling Data

```{r}
split_data <- function(dat, splits=c(.5, .5), fudge=1) {
  stopifnot(all(splits) >= 0, fudge <= length(splits))
  splits <- (splits / sum(splits))
  n_dat_sum <- round(nrow(dat) * splits)
  n_dat_sum[fudge] <- (nrow(dat) - sum(n_dat_sum[-fudge]))
  split(dat, sample(rep(1:length(splits), n_dat_sum)))
}
```

Examples of `split_data` below...

```{r}
split_data(mtcars) # 50/50 split by default
split_data(mtcars, splits=c(.2, .4, .3, .1)) # 20/40/30/10 split≈
```

###### Plotting

Example of normal quantile plots...

```{r}
qq_example_x <- c(21.7, 22.6 , 26.1, 28.3, 30, 31.2, 31.5, 33.5, 34.7, 36)
qqnorm(qq_example_x)        # plot points to the quantiles of the standard normal on the x axis. 
qqline(qq_example_x)        # adds a straight line through the first and thrid quartiles of the data. 
```

Plotting empirical cumulative distribution functions...

```{r}
empirical_example_x <- c(3, 6, 15, 15, 17, 19, 24) 
plot.ecdf(empirical_example_x) 
empirical_example_x <- rnorm(25) 
plot.ecdf(empirical_example_x, xlim = c(-4, 4))                 # adjust x range 
# curve(pnorm(empirical_example_x), col = "blue" , add = TRUE)  # impose normal cdf  
# abline(v = 25, col = "red")                                   # add vertical line
```

Observed Mean difference 

```{r}
#tapply(x$y, z$y, mean)  #example, no data though :( 
#observed <- output of one minus the other
```



10. bascially asking for a being able to test a single population - 
    stating null and hypothesis
    EXAMPLE: pg 35
        mice going through the maze - 
        null - there is no difference (mew zero)
        alternative - there is a difference (mew D) one variable (drug in this case) has an effect
    meanA - meanB
    #this is numberical 


    drug <- c(30, 25, 20)
    cont <- c(18, 21, 22)
    
    all <- c(drug, cont)

    mean difference - 6 c 3 ways to get the numbers 
        calc observed value - mean of drug(mice drug) - mean of control(normal mice)
    use gtools
    combo <- combinations(n, r, v=1:n, set=T,)
    combo <- combinations(6, 3, v=all, set=T,)
    #exact - use the function (mew of d - mew of c) -> mean(drug) - mean(cont)
    # observed == test statistic of original distribution
    # p-value <- length(z(x >= observed value)) / 20 =>(6 c 3)
    
    # approximate_way <-  sd(all) / sqrt(length(all))
    
    
10.B benoulli <- Boolean values (true false, head/tails, Yes/No)
     find test statistic - probably the amount in each group 
     group1 - vote 300 yes
     group2 - vote 200 yes
     
     test-statistic = group1 - group2
     
     #after getting test stat 
     find the observed value <- group 1 - group2
     exact <- combination(n, r, 1:n, set = T, )
     
     approx <- sqrt((weight(1 -weight))/500(from both yes)) 
 
 11. 
---
### Examples of basic r functions and their meanings

choose n numbers between min x and max y
```{r}
runif(4, min=3, max=13)
```
Select n random normally chosen integers
```{r}
rnorm(10)
```
randomly sample vector v into new vector of size n
```{r}
x <- 10:14
sample(x, size=4)
```
**Permutations**: 
- order matters
- P(n,k) = n!/(n-k)!
**Combinations**:
- order doesnt matter
- C(n,k) = n!/(n-k)!k!

```{r}
# src size, dst size, vector, remove duplicates
y <- 1:100
permutations(8,4,y, set=FALSE)
#yeilds 1680 permutations

#same params as permutate
combinations(8,4,y, set=FALSE)
#yeilds 70 combinations
```

```{r}
```


---

### Vocab

1.  **Observational Study**: observing a group without influencing it.
2.  **Designed Experiment**: applies something to a group and sees what it does.
3.  **Response Variable**: What is being checked in an experiment.
4.  **Explanatory Variable**: the reason for a change occuring.
5.  **Factor**: an explanatory variable you manipulate.
6.  **Factor level**: The variations used for the variable.
7.  **Treatment**: Factor levels combined.
8.  **Randomization**: using chance to assign patients to treatments.
9.  **Replication**: reproducing earlier test results again.
10. **Binding**: preventing specific test knowledge from becoming public.
11. **Single Bind**: subjects dont know if they have treatment or placebo.
12. **Double Bind**: subjects and experimenters dont know who gets placebo and who gets treatment.
13. **Confounding**: Experiment is setup such that experimenter cant remove other alternatives for a relationship between dependent and independent.
14. **Covariate**: something you track from the beginning but isnt your goal to track.
15. **CRD (complete random design)**: subjects randomly assigned to treatments.
![Complete Random Design](http://image.slidesharecdn.com/statschapter5-101115133012-phpapp01/95/stats-chapter-5-37-638.jpg?cb=1422659014)
16. **RCBD (random complete block design**: grouping experimental units that are similar before applying random testing
![Random Complete Block Design](http://d3e3jwjal5zk9x.cloudfront.net/content/jexbio/208/7/1267/F1.large.jpg)
17. **MPD (match pair design)**: when experiment has 2 treatment conditions subjects are grouped into pairs then assigned different treatments
![Matched Pair Design](http://image.slidesharecdn.com/statschapter5-101115133012-phpapp01/95/stats-chapter-5-44-638.jpg?cb=1422659014)
18. **ANOVA**: Analysis of variants.
19. **1-way ANOVA**: used to see if there are differences between the means of 2 or more unrelated groups. It tests the null hypothesis. Accept alternative hypothesis if ANOVA gives signifigant result.
20. **2-way ANOVA**: used to determine mean between groups that have been split on 2 independent factors. trying to understand if there is a difference in teh interaction of 2 independent variables.
21. **MANOVA**: 1 way anova with many dependent vars.
22. **ANCOVA**: analysis of covariance, 1 way ancova w/ a covariate.
23. **Null Hypothesis**: ($H_O$) A statement that corresponds to no real effect.
24. **Alternate hypothesis**: ($H_A$) statement that there is a real effect.
25. **Test Statistic**: ($T$) numerical function of dota whose value determines result of the test
26. **Reference Distribution**: same thing as the null distrubution - the exact or approximate distribution of the test statistic.
27. **P-value**: probability that observed data satisfies the alternate hypothesis.
28. **Level of Significance**: ($\alpha$) p-value percentage which defines when we should accept/reject null hypothesis. _The max probability for receiving a type-1 error is equal to the level of significance._
29. **Type 1 Error**: Rejecting a true Null Hypothesis.
30. **Type 2 Error**: Not rejecting a false Null Hypothesis.



### Approximate Reference Distribution Equations


|Testing Procedure|Data Type|Test Statsistic|Exact Reference Distribution|Approximate Reference Distribution|Null Hypothesis|
|:--:|:--:|:--:|:--:|:--:|:--:|
|Population mean $\mu$|Numerical|Sample mean $\hat{x}$|The distribution of all possible values of $\hat{x}$ under $H_O$|$N(\mu_O, \frac{\delta}{\sqrt{n}})$|$H_O: \mu=\mu_O$|
|Population portion $P$|Bernoulli|Sample porportion $\hat{P}$|The distribution of all possible values of $\hat{P}$ under $H_O$|$N(\mu_O, \sqrt{\frac{P_O*(1-P_O)}{n}})$|$H_O: P=P_O$|

---

### Activity 5

1. _The R codes that will store the data from the AsULearn file `StudentProfile.csv` in a data frame called designdata, display the first few rows of the data frame and count the number of cases_
TLDR: reads file, displays first couple

```{r}
student_profile_csv <- "Student,Sex,Class,Grade
Mary,F,F,A
James,M,So,A
Linda,F,J,A
Alice,F,Se,B
Lindsay,F,Se,C
Ben,M,J,A
Jane,F,So,C
Christy,F,F,B
Mike,M,J,A
Steve,M,So,B
Paul,M,Se,B
Janet,F,J,B
Vicky,F,F,C
Roman,M,F,D
Victoria,F,J,A
Luke,M,J,F
Maddie,F,J,C
Evan,M,Se,D
Ruby,F,Se,C
Miranda,F,J,B
Cole,M,So,A
Kelsie,F,Se,F
Alex,M,F,B
Grace,F,So,C
Matt,M,J,C
Dona,F,F,D
Madelyn,F,Se,B
Stephen,M,J,C
David,M,F,C
Mandy,F,J,D"
designdata <- read.csv(textConnection(student_profile_csv))
head(designdata)    # head print out the first few entries
nrow(designdata)    # prints out the number of rows 
```

2. _The R codes for a function that will randomly select about half of the experimental units stored in a vector x, assigns them to treatment 1 and then assigns the remaining experimental units to treatment 2. The output of the function should display the entries of the vector that are assigned to each of the two treatments._
TLDR: 2 way ANOVA, CRD

```{r}
assignrand <- function(x) 
{
  half     <- floor(length(x)/2);
  indicies <- sample(1:length(x), half)
  t1 <- x[indicies]
  t2 <- x[-indicies]
  cat("Treatment1: ", t1, "\n")
  cat("Treatment2: ", t2)
  return(list(t1, t2))
}
```

3. _The R codes that use the function in **#2** to randomly assign the students in the data frame to two treatments. The output of the R codes should display the names assigned to each of the two treatments._

```{r}
treatments = assignrand(levels(designdata$Student))
print(treatments[1])
print(treatments[2])
```

4. _A paragraph discussing why the method of assigning the students to the two treatments in #3 is called Completely Randomized Design._

Completely Randomized Design (CRD) is a design where the treatments allocated are completely random. Using the “sample” command, R chose which student received which treatment randomly. We randomly assign them to the two treatments without trying to balance for any confounding variables. This way, (in theory) one entire group could end up being female and the other male. This could skew the data, depending on what we’re studying. To avoid having skewed data, one could include additional CRD’s through the block design for each variable that might affect the test.
Ans: Completely Randomized Design (CRD) is a design where the treatments allocated are completely random. Using the “sample” command, R chose which student received which treatment randomly. We randomly assign them to the two treatments without trying to balance for any confounding variables. This way, (in theory) one entire group could end up being female and the other male. This could skew the data, depending on what we’re studying. To avoid having skewed data, one could include additional CRD’s through the block design for each variable that might affect the test.


5. _The R codes that will help you answer which of the two treatment groups in **#3** contain more A students. The R codes should display the answer together with a supporting graph and/or statistics._

```{r}
treatments <- assignrand((1:nrow(designdata)))

treatment1Population <- designdata[unlist(treatments[1]),]
treatment2Population <- designdata[unlist(treatments[2]),]

treatment1a <- which(treatment1Population$Grade == 'A')
numA1 <- length(treatment1a)
treatment2a <- which(treatment2Population$Grade == 'A')
numA2 <- length(treatment2a)

if (numA1 > numA2) {
  cat("Treatment 1 has more A students than treatment 2.\n")
} else if (numA1 == numA2) {
  cat("Both treatements have an equal number of A students.\n")
}else {
  cat("Treatment 2 has more A students than treatement 1.\n")
}

ftable(treatment1Population$Grade)  # ftable == flat contengency table 
ftable(treatment2Population$Grade)

par(mfrow=c(1,2)) # par == sets parameters for graphs this means 1 row and 2 columns
plot(treatment1Population$Grade, main="Grades of Students\nReceiving Treatment 1", xlab='Grade', ylab='Frequency')
plot(treatment2Population$Grade, main='Grades of Students\nReceiving Treatment 2', xlab='Grade', ylab='Frequency')
```

6. The R codes that will implement a Randomized Complete Block Design with the students in the data frame as the experimental units and with sex as a blocking variable. The R codes should use the function in **#3** in assigning the students in a block to the two treatments. The output of the R codes should display the names of the students, the block where the student belongs to and the treatment where the students were assigned to._

```{r}
male = transform(subset(designdata, subset=Sex == 'M'), Block = 'Male')     # transform == adds entry to a table
female = transform(subset(designdata, subset=Sex == 'F'), Block = 'Female')
maleTreatments = assignrand(1:nrow(male))

femaleTreatments = assignrand(1:nrow(female))

maleT1 = transform(male[unlist(maleTreatments[1]),], Treatment=1)
maleT2 = transform(male[unlist(maleTreatments[2]),], Treatment=2)
femaleT1 = transform(female[unlist(femaleTreatments[1]),], Treatment=1)
femaleT2 = transform(female[unlist(femaleTreatments[2]),], Treatment=2)

augmentedData = rbind(maleT1, maleT2, femaleT1, femaleT2)
subset(augmentedData, select = c(Student, Block, Treatment))
```

7. _The R codes that will help you answer which of the two treatment groups in the male block contain more A students. The R codes should display the answer with a supporting graph and/or statistics._

```{r}
male<-subset(augmentedData, Sex=='M')
maleone<-subset(male, Treatment=='1')
maletwo<-subset(male, Treatment=='2')
treatmentmaleone<-which(maleone$Grade=='A')
numA1<-length(treatmentmaleone)
treatmentmaletwo<-which(maletwo$Grade=='A')
numA2<-length(treatmentmaletwo)
if (numA1 > numA2) {
  cat("Treatment 1 has more A students than treatment 2.\n")
} else if (numA1 == numA2) {
  cat("Both treatements have an equal number of A students.\n")
}else {
  cat("Treatment 2 has more A students than treatement 1.\n")
}

par(mfrow=c(1,2))
plot(maletwo$Grade, main='Grades of Male Students Receiving Treatment Two', xlab='Grade', ylab='Frequency')
plot(maleone$Grade, main='Grades of Male Students Receiving Treatment One', xlab='Grade', ylab='Frequency')
```

8. _The R codes that will help you answer which of the two treatment groups in the female block contain more A students. The R codes should display the answer with a supporting graph or statistics._
TLDR: which contains more

```{r}
female<-subset(augmentedData, Sex=='F')
femaleone<-subset(female, Treatment=='1')
femaletwo<-subset(female, Treatment=='2')
treatmentfemaleone<-which(femaleone$Grade=='A')
numA1<-length(treatmentfemaleone)
treatmentfemaletwo<-which(femaletwo$Grade=='A')
numA2<-length(treatmentfemaletwo)
if (numA1 > numA2) {
  cat("Treatment 1 has more A students than treatment 2.\n")
} else if (numA1 == numA2) {
  cat("Both treatements have an equal number of A students.\n")
}else {
  cat("Treatment 2 has more A students than treatement 1.\n")
}

par(mfrow=c(1,2))
plot(femaleone$Grade, main='Grades of Female Students Receiving Treatment One', xlab='Grade', ylab='Frequency')
plot(femaletwo$Grade, main='Grades of Female Students Receiving Treatment Two', xlab='Grade', ylab='Frequency')
```

9. _The R codes that will identify three unique pairs of students that are matched by sex and by class. The output of the R codes should display the three pairs of matched students._

```{r}
classLevels = levels(augmentedData$Class)
sexLevels = levels(augmentedData$Sex)
pairs = c()
for (i in 1:length(classLevels)) {
  for (j in 1:length(sexLevels)) {
    #segment the data by a given factor
    cohort = subset(augmentedData,
                     Sex == sexLevels[j] & Class == classLevels[i])
    cat("class:", classLevels[i], "sex:", sexLevels[j], "number: ", nrow(cohort), "\n")
    indicies = sample(nrow(cohort), size=2, replace=F)
    selection1 = strtoi(rownames(cohort[indicies[1],]))
    selection2 = strtoi(rownames(cohort[indicies[2],]))
    #this gives us all eight pairs. each pair is a column
    pairs = cbind(pairs, c(selection1, selection2)) # cbind -> is column binding 
  }
}

chosen = sample(8, size=3)
#These are row numbers in the original dataframe
print(pairs[,chosen])
```

10. _The R codes that will randomly assign each of the student in a pair identified in **#9** to one of two treatments. The R codes should display the resulting treatment assignments and should identify which of the two resulting treatment groups has more A students with supporting graph and/or statistics._

```{r}
finalPairs = pairs[,chosen]

assignrandpairs = function(x) {
  t1 = list()
  t2 = list()
  for (i in 1:3) {
    randTreatOne = sample(1:2, size=1)
    t1temp = finalPairs[randTreatOne, i]
    t1 = c(t1, t1temp)
    t2temp = finalPairs[-randTreatOne, i]
    t2 = c(t2, t2temp)
  }
  return(list(t1, t2))
}
treatments = assignrandpairs(finalPairs)
print(treatments[1])

print(treatments[2])

treatment1Population = designdata[unlist(treatments[1]),]
treatment2Population = designdata[unlist(treatments[2]),]

treatment1a = which(treatment1Population$Grade == 'A')
numA1 = length(treatment1a)
treatment2a = which(treatment2Population$Grade == 'A')
numA2 = length(treatment2a)

if (numA1 > numA2) {
  cat("Treatment 1 has more A students than treatment 2.\n")
} else if (numA1 == numA2) {
  cat("Both treatements have an equal number of A students.\n")
}else {
  cat("Treatment 2 has more A students than treatement 1.\n")
}

ftable(treatment1Population$Grade)

ftable(treatment2Population$Grade)

par(mfrow=c(1,2))
plot(treatment1Population$Grade, main="Grades of Students\nReceiving Treatment 1", xlab='Grade', ylab='Frequency')
plot(treatment2Population$Grade, main='Grades of Students\nReceiving Treatment 2', xlab='Grade', ylab='Frequency')
```


---

### Activity 6


Consider an experiment with 2 treatments, say Placebo and New Cholesterol Lowering Drug.   Suppose the cholesterol level measurements were as follows:

|Placebo|Drug|
|:-----:|:--:|
|29, 25, 22|18, 23, 28|

If there is no difference between the placebo and the drug, these 6 measurements can be treated as a random assignment to the two treatments.  Find the remaining random allocations of these 6 measurements to the 2 treatment groups and complete the following table:  (Round the difference in means to the nearest 2 decimal place)

```{r}
library(gtools)

values = c(29,25,22,18,23,28)
indicies = combinations(length(values), 3, 1:length(values))
diffMeans = list()
for(i in 1:(length(indicies[,1]))) {
  diffMeans = c(diffMeans, mean(values[indicies[i,]])-mean(values[-indicies[i,]]))
  cat(
    i,
    ":",
    values[indicies[i,]],
    "\t",
    values[-indicies[i,]],
    "\t",
    mean(values[indicies[i,]])-mean(values[-indicies[i,]]),
    "\n"
  )
}
```

1. _Attach a histogram of the permutation distribution of the difference in means (the test statistic).   Would you say that this distribution is approximately normal?_

```{r}
diffMeans = unlist(diffMeans)
diffMeans = unlist(diffMeans)
hist(diffMeans, freq=F, xlab="Difference in the Means", main= "Histogram of the Differences in the Means")

```
This distribution looks incredibly normal, but all possible combinations ought to yield a normal distribution, so this isn’t surprising.


2. _Assuming the permutation distribution in **#1** can be approximated by a Normal distribution, what would be its mean and standard deviation?_

```{r}
cat("mean: ", mean(diffMeans), "\n")
cat("sd: ", sd(diffMeans))
```

3. _What percent of the possible allocations yield a difference equal to or higher than the difference in the original observed data? This is the exact `p-value` of the permutation test for no difference between the two treatments. Discuss what this `p-value` means in the context of the experiment._

```{r}
originalDifference = mean(c(29,25,22))-mean(c(18,23,28))
higher = which(diffMeans >= originalDifference)
percentHigher = length(higher)/length(diffMeans)*100
cat(percentHigher, "% of the allocations are higher than ", originalDifference, "\n", sep="")
```
The p-value, in this experiment, represents the chance that the difference between the results of the two treatments occurred randomly. Specifically, this experiment measures the cholesterol of the participants. The p-value here measures whether the cholesterol of the participants changed (or didn’t change) randomly or due to the treatment.

4. _Calculate the approximate `p-value` of a test of no difference between the treatments based on the Normal approximation in **#2**. Is this p-value reasonably close to the exact `p-value` in **#3**?_

```{r}
pval = 1-pnorm(originalDifference, mean=0, sd=sd(diffMeans))
ppercent = 100*pval
cat("In a normal distribution, ", ppercent, "% of the data is higher than ", originalDifference, "\n", sep="")

cat("This is ", percentHigher - ppercent, "% higher than the p-value of the data's combinations.\n", sep="")
```

5. _Investigate and discuss how the variability of the data affects the `p-value`. You can use the Normal approximation to the permutation distribution with varying standard deviations to help you answer this question or you can modify the data._

```{r}
pval2 = 1-pnorm(originalDifference, mean=0, sd=sd(diffMeans)+1)
ppercent2 = 100*pval2
pval3 = 1-pnorm(originalDifference, mean=0, sd=sd(diffMeans)-1)
ppercent3 = 100*pval3
cat("If you increase the standard deviation by 1, the pvalue becomes ", pval2, "\n", sep="")

cat("If you decrease the standard deviation by 1, the pvalue becomes ", pval3, "\n", sep="")
```
When you decrease the variability, the p-value decreases. This makes sense because the less variable the data is, the lower the likelihood of randomly getting a result far from the mean becomes.

---

### Activity 7

1. _Use the combinations command within the gtools package to find all the other random allocations of these 8 observations to the 2 treatment groups. Display the first 20 such allocations and the values of the test statistic `T` = Difference in Proportions of Lows (Drug Proportion – Placebo Proportion)._

```{r}
x <- c('H','H','H','L','L','L','L','H')
y <- seq(1:8)
z <- combinations(8,4,y)
Drug <- z
Placebo <- z
Difference <- vector(mode = "numeric", length = 0)
for(i in 1:length(z[,1]))
{
  Drug[i,] <- x[z[i,]]
  Placebo[i,] <- x[-z[i,]]
}
for(i in 1:length(z[,1]))
{
  Difference[i] <- ((length(which(Drug[i,] == 'L'))/4) 
                    - (length(which(Placebo[i,] == 'L'))/4))
}
m <- cbind(Drug, Placebo, Difference)
m[1:20,]
```

2. _The exact reference permutation distribution of the test statistic `T` if there is no difference between the two treatments is the distribution of all possible values of `T` for all possible allocations of the 8 observations to the 2 treatments. How many possible allocations are there?_

```{r}
length(z[,1])
```
There are seventy possible allocations for the 8 variables in the two treatment groups.


3. _Based on the original data, what is the standard deviation of the approximate reference distribution of the test statistic `T` if there is no difference between the drug and the placebo?_

```{r}
s <- sqrt(0.5*(1-0.5)*((1/4) + (1/4)))
s
```

4. _Draw the approximate reference distribution of the test statistic `T` if there is no difference between the two treatments. Label the points in the horizontal axis that lie 1, 2 and 3 standard deviations below and above the mean._

```{r}
g <- seq(-1.5,1.5, by = .01)
plot(g,dnorm(g, 0, s), type = 'l', col = 'blue')
b <- c(-3*s, -2*s, -s, s, 2*s, 3*s)
abline(v = b, col = 'red')
```

5. _Calculate the observed value of the test statistic `T` from the original data._

```{r}
t = ((1/4) - (3/4))
t
```

6. _Calculate the `p-value` of the test of no difference between the two treatments._

```{r}
p <- 1 - pnorm(t, 0, s)
p
```

7. _State the null $H_O$ and alternative hypotheses $H_A$ in the context of the study._

$H_O$, the null hypothesis, would say there is no difference in the drug and the placebo. Neither will offer an outcome that is significantly different from the other. $H_A$, the alternate hypothesis, would claim that the actual drug would result in a decrease in cholesterol, while the placebo would not change a person’s cholesterol significantly.



8. _Interpret the p-value in the context of the study if the level of significance is `.05`._

With a level of significance of .05, the p-value indicates that there is no remarkable difference in the drug and the placebo. Therefore we can accept the null hypothesis.


9. _Interpret the p-value in the context of the study if the level of significance is `.01`._

With a level of significance of .01, again the p-value indicates that there is no meaningful difference in the two treatments.


10. _At the level of significance of .01, what is the largest observed value of the test statistic T that won’t lead to the rejection of Ho?_

```{r}
c <- seq(-1, 1, by = 0.5)
p <- 1 - pnorm(c, 0, s)
p

c[which.max(c[which(p >= 0.01)])]
```

The largest observed value of the test statistic that will not lead to the rejection of the null hypothesis is 0.5.